# -*- coding: utf-8 -*-
"""AIMUSIC

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kB76ZAPADhOeyZ2fYYXYr6ts-arR09Bs
"""

import streamlit as st
import glob
import random
import numpy as np
import tensorflow as tf
from music21 import converter, instrument, note, chord, stream, tempo, meter, key, expressions
from keras.models import Sequential
from keras.layers import Dense, Dropout, LSTM, Bidirectional
from keras.utils import to_categorical
import copy
import os

# Seed
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# Cấu hình
KEY = 'C'
SCALE_NOTES = ['C', 'D', 'E', 'F', 'G', 'A', 'B']
OCTAVE_RANGE = [4, 5]
TEMPO = 100

MAIN_PITCHES = []

# MIDI Parsing
def get_notes(midi_folder: str) -> list[str]:
    notes = []
    for file in glob.glob(f"{midi_folder}/*.mid"):
        midi = converter.parse(file)
        try:
            parts = instrument.partitionByInstrument(midi)
            notes_to_parse = parts.parts[0].recurse()
        except:
            notes_to_parse = midi.flat.notes
        for element in notes_to_parse:
            if isinstance(element, note.Note):
                notes.append(str(element.pitch))
            elif isinstance(element, chord.Chord):
                notes.append(".".join(str(n) for n in element.normalOrder))
    return notes

def prepare_sequences(notes: list[str], n_vocab: int, sequence_length: int = 100):
    pitchnames = sorted(set(notes))
    note_to_int = {n: i for i, n in enumerate(pitchnames)}
    network_input, network_output = [], []
    for i in range(len(notes) - sequence_length):
        seq_in = notes[i : i + sequence_length]
        seq_out = notes[i + sequence_length]
        seq_in_norm = [note_to_int[n] / n_vocab for n in seq_in]
        network_input.append(np.expand_dims(seq_in_norm, axis=-1))
        network_output.append(note_to_int[seq_out])
    return np.array(network_input), to_categorical(network_output, num_classes=n_vocab), pitchnames

def create_network(input_shape, n_vocab: int) -> Sequential:
    model = Sequential([
         LSTM(512, input_shape=input_shape, return_sequences=True),
        Dropout(0.3),
        Bidirectional(LSTM(512, return_sequences=True)),
        Dropout(0.3),
        Bidirectional(LSTM(512)),
        Dense(256, activation="relu"),
        Dropout(0.3),
        Dense(n_vocab, activation="softmax"),
    ])
    model.compile(loss="categorical_crossentropy", optimizer="adam")
    return model

def get_main_pitches(key: str = "C", scale_notes: list[str] = SCALE_NOTES, octaves: list[int] = OCTAVE_RANGE) -> list[str]:
    pitches = []
    for octave in octaves:
        for note_name in scale_notes:
            pitches.append(f"{note_name}{octave}")
    return pitches

def generate_melody_section(length: int = 32, use_motif=False, motif=None, style='pop'):
    section = []
    prev_note = None
    i = 0

    if style == 'pop_edm':
        durations = [0.25, 0.5, 0.5, 1.0]
        rest_prob = 0.05
        chord_prob = 0.5
        pitch_range = (65, 76)
    elif style == 'pop_chill':
        durations = [1.0, 1.5, 2.0]
        rest_prob = 0.25
        chord_prob = 0.2
        pitch_range = (60, 69)
    else:
        durations = [0.5, 1.0, 1.0, 1.5]
        rest_prob = 0.15
        chord_prob = 0.3
        pitch_range = (60, 72)

    while i < length:
        dur = random.choice(durations)

        if use_motif and motif:
            motif_notes = [copy.deepcopy(n) for n in motif if isinstance(n, note.Note) and pitch_range[0] <= n.pitch.midi <= pitch_range[1]]
            if motif_notes:
                n = copy.deepcopy(motif_notes[i % len(motif_notes)])
                n.duration.quarterLength = dur
                section.append(n)
                prev_note = n
                i += 1
                continue

        if random.random() < rest_prob:
            section.append(note.Rest(quarterLength=dur))
            prev_note = None
            i += 1
            continue

        if random.random() < chord_prob:
            chord_notes = []
            tries = 0
            while len(chord_notes) < 2 and tries < 20:
                p_str = random.choice(MAIN_PITCHES)
                p = note.Note(p_str)
                if not prev_note or abs(p.pitch.midi - prev_note.pitch.midi) <= 7:
                    if pitch_range[0] <= p.pitch.midi <= pitch_range[1]:
                        chord_notes.append(p)
                        prev_note = p
                tries += 1
            if chord_notes:
                c = chord.Chord(chord_notes)
                c.duration.quarterLength = dur
                section.append(c)
                i += 1
            continue

        tries = 0
        while tries < 10:
            p_str = random.choice(MAIN_PITCHES)
            p = note.Note(p_str)
            if not prev_note or abs(p.pitch.midi - prev_note.pitch.midi) <= 7:
                if pitch_range[0] <= p.pitch.midi <= pitch_range[1]:
                    p.duration.quarterLength = dur
                    section.append(p)
                    prev_note = p
                    break
            tries += 1
        i += 1

    return section

def generate_structure(style: str):
    melody = stream.Part()
    melody.append(tempo.MetronomeMark(number=TEMPO))
    melody.append(meter.TimeSignature("4/4"))
    melody.append(key.Key(KEY))
    melody.append(instrument.Piano())

    hook_motif = generate_melody_section(8, use_motif=False, style=style)

    structure = [
        ("Intro", 8, False),
        ("Verse1", 32, False),
        ("Hook", 16, True),
        ("Verse2", 32, False),
        ("Outro", 8, True),
    ]

    for name, length, use_motif in structure:
        melody.append(expressions.TextExpression(f'[{name}]'))
        section = generate_melody_section(length=length, use_motif=use_motif, motif=hook_motif, style=style)
        for n in section:
            melody.append(n)

    return melody

def save_midi(melody_stream: stream.Stream, filename: str):
    melody_stream.write("midi", fp=filename)

# -------------------- STREAMLIT APP --------------------

st.set_page_config(page_title="🎵 Pop Melody Generator", layout="centered")
st.title("🎼 Trình tạo nhạc Pop bằng LSTM")

style = st.selectbox("Chọn phong cách nhạc", ['pop', 'pop_edm', 'pop_chill'])

midi_folder = st.text_input("📁 Đường dẫn thư mục chứa file MIDI huấn luyện", value="midi")

if st.button("🎹 Bắt đầu huấn luyện & sinh nhạc"):
    if not os.path.exists(midi_folder):
        st.error("❌ Thư mục không tồn tại.")
    else:
        st.info("⏳ Đang huấn luyện mô hình và sinh nhạc...")
        notes = get_notes(midi_folder)
        n_vocab = len(set(notes))
        network_input, network_output, _ = prepare_sequences(notes, n_vocab)
        model = create_network(network_input.shape[1:], n_vocab)
        model.fit(network_input, network_output, epochs=2, batch_size=64)
        model.save("lstm_music_model.keras")
        st.success("✅ Đã huấn luyện mô hình xong!")

        MAIN_PITCHES.clear()
        MAIN_PITCHES.extend(get_main_pitches(KEY))

        melody = generate_structure(style=style)
        save_midi(melody, "generated_pop_music.mid")
        st.success("✅ Đã tạo xong giai điệu!")

        with open("generated_pop_music.mid", "rb") as f:
            st.download_button("📥 Tải file MIDI", f, file_name="generated_pop_music.mid")