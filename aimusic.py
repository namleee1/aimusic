# -*- coding: utf-8 -*-
"""AIMUSIC

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kB76ZAPADhOeyZ2fYYXYr6ts-arR09Bs
"""

import streamlit as st
import glob
import random
import numpy as np
import tensorflow as tf
from music21 import converter, instrument, note, chord, stream, tempo, meter, key, expressions
from keras.models import Sequential
from keras.layers import Dense, Dropout, LSTM, Bidirectional
from keras.utils import to_categorical
import copy
import os

# Seed
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

# Cáº¥u hÃ¬nh
KEY = 'C'
SCALE_NOTES = ['C', 'D', 'E', 'F', 'G', 'A', 'B']
OCTAVE_RANGE = [4, 5]
TEMPO = 100

MAIN_PITCHES = []

# MIDI Parsing
def get_notes(midi_folder: str) -> list[str]:
    notes = []
    for file in glob.glob(f"{midi_folder}/*.mid"):
        midi = converter.parse(file)
        try:
            parts = instrument.partitionByInstrument(midi)
            notes_to_parse = parts.parts[0].recurse()
        except:
            notes_to_parse = midi.flat.notes
        for element in notes_to_parse:
            if isinstance(element, note.Note):
                notes.append(str(element.pitch))
            elif isinstance(element, chord.Chord):
                notes.append(".".join(str(n) for n in element.normalOrder))
    return notes

def prepare_sequences(notes: list[str], n_vocab: int, sequence_length: int = 100):
    pitchnames = sorted(set(notes))
    note_to_int = {n: i for i, n in enumerate(pitchnames)}
    network_input, network_output = [], []
    for i in range(len(notes) - sequence_length):
        seq_in = notes[i : i + sequence_length]
        seq_out = notes[i + sequence_length]
        seq_in_norm = [note_to_int[n] / n_vocab for n in seq_in]
        network_input.append(np.expand_dims(seq_in_norm, axis=-1))
        network_output.append(note_to_int[seq_out])
    return np.array(network_input), to_categorical(network_output, num_classes=n_vocab), pitchnames

def create_network(input_shape, n_vocab: int) -> Sequential:
    model = Sequential([
         LSTM(512, input_shape=input_shape, return_sequences=True),
        Dropout(0.3),
        Bidirectional(LSTM(512, return_sequences=True)),
        Dropout(0.3),
        Bidirectional(LSTM(512)),
        Dense(256, activation="relu"),
        Dropout(0.3),
        Dense(n_vocab, activation="softmax"),
    ])
    model.compile(loss="categorical_crossentropy", optimizer="adam")
    return model

def get_main_pitches(key: str = "C", scale_notes: list[str] = SCALE_NOTES, octaves: list[int] = OCTAVE_RANGE) -> list[str]:
    pitches = []
    for octave in octaves:
        for note_name in scale_notes:
            pitches.append(f"{note_name}{octave}")
    return pitches

def generate_melody_section(length: int = 32, use_motif=False, motif=None, style='pop'):
    section = []
    prev_note = None
    i = 0

    if style == 'pop_edm':
        durations = [0.25, 0.5, 0.5, 1.0]
        rest_prob = 0.05
        chord_prob = 0.5
        pitch_range = (65, 76)
    elif style == 'pop_chill':
        durations = [1.0, 1.5, 2.0]
        rest_prob = 0.25
        chord_prob = 0.2
        pitch_range = (60, 69)
    else:
        durations = [0.5, 1.0, 1.0, 1.5]
        rest_prob = 0.15
        chord_prob = 0.3
        pitch_range = (60, 72)

    while i < length:
        dur = random.choice(durations)

        if use_motif and motif:
            motif_notes = [copy.deepcopy(n) for n in motif if isinstance(n, note.Note) and pitch_range[0] <= n.pitch.midi <= pitch_range[1]]
            if motif_notes:
                n = copy.deepcopy(motif_notes[i % len(motif_notes)])
                n.duration.quarterLength = dur
                section.append(n)
                prev_note = n
                i += 1
                continue

        if random.random() < rest_prob:
            section.append(note.Rest(quarterLength=dur))
            prev_note = None
            i += 1
            continue

        if random.random() < chord_prob:
            chord_notes = []
            tries = 0
            while len(chord_notes) < 2 and tries < 20:
                p_str = random.choice(MAIN_PITCHES)
                p = note.Note(p_str)
                if not prev_note or abs(p.pitch.midi - prev_note.pitch.midi) <= 7:
                    if pitch_range[0] <= p.pitch.midi <= pitch_range[1]:
                        chord_notes.append(p)
                        prev_note = p
                tries += 1
            if chord_notes:
                c = chord.Chord(chord_notes)
                c.duration.quarterLength = dur
                section.append(c)
                i += 1
            continue

        tries = 0
        while tries < 10:
            p_str = random.choice(MAIN_PITCHES)
            p = note.Note(p_str)
            if not prev_note or abs(p.pitch.midi - prev_note.pitch.midi) <= 7:
                if pitch_range[0] <= p.pitch.midi <= pitch_range[1]:
                    p.duration.quarterLength = dur
                    section.append(p)
                    prev_note = p
                    break
            tries += 1
        i += 1

    return section

def generate_structure(style: str):
    melody = stream.Part()
    melody.append(tempo.MetronomeMark(number=TEMPO))
    melody.append(meter.TimeSignature("4/4"))
    melody.append(key.Key(KEY))
    melody.append(instrument.Piano())

    hook_motif = generate_melody_section(8, use_motif=False, style=style)

    structure = [
        ("Intro", 8, False),
        ("Verse1", 32, False),
        ("Hook", 16, True),
        ("Verse2", 32, False),
        ("Outro", 8, True),
    ]

    for name, length, use_motif in structure:
        melody.append(expressions.TextExpression(f'[{name}]'))
        section = generate_melody_section(length=length, use_motif=use_motif, motif=hook_motif, style=style)
        for n in section:
            melody.append(n)

    return melody

def save_midi(melody_stream: stream.Stream, filename: str):
    melody_stream.write("midi", fp=filename)

# -------------------- STREAMLIT APP --------------------

st.set_page_config(page_title="ðŸŽµ Pop Melody Generator", layout="centered")
st.title("ðŸŽ¼ TrÃ¬nh táº¡o nháº¡c Pop báº±ng LSTM")

style = st.selectbox("Chá»n phong cÃ¡ch nháº¡c", ['pop', 'pop_edm', 'pop_chill'])

midi_folder = st.text_input("ðŸ“ ÄÆ°á»ng dáº«n thÆ° má»¥c chá»©a file MIDI huáº¥n luyá»‡n", value="midi")

if st.button("ðŸŽ¹ Báº¯t Ä‘áº§u huáº¥n luyá»‡n & sinh nháº¡c"):
    if not os.path.exists(midi_folder):
        st.error("âŒ ThÆ° má»¥c khÃ´ng tá»“n táº¡i.")
    else:
        st.info("â³ Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh vÃ  sinh nháº¡c...")
        notes = get_notes(midi_folder)
        n_vocab = len(set(notes))
        network_input, network_output, _ = prepare_sequences(notes, n_vocab)
        model = create_network(network_input.shape[1:], n_vocab)
        model.fit(network_input, network_output, epochs=2, batch_size=64)
        model.save("lstm_music_model.keras")
        st.success("âœ… ÄÃ£ huáº¥n luyá»‡n mÃ´ hÃ¬nh xong!")

        MAIN_PITCHES.clear()
        MAIN_PITCHES.extend(get_main_pitches(KEY))

        melody = generate_structure(style=style)
        save_midi(melody, "generated_pop_music.mid")
        st.success("âœ… ÄÃ£ táº¡o xong giai Ä‘iá»‡u!")

        with open("generated_pop_music.mid", "rb") as f:
            st.download_button("ðŸ“¥ Táº£i file MIDI", f, file_name="generated_pop_music.mid")